# EE569 CarRacing-v3: SAC Implementation for Autonomous Racing

## ðŸ“‹ Project Overview
This repository contains a complete implementation of **Soft Actor-Critic (SAC)** for the **CarRacing-v3** environment from Gymnasium.  
The agent learns autonomous driving directly from **raw pixel inputs (84Ã—84 grayscale frames)** using deep reinforcement learning.

- **Course:** EE569 Deep Learning  
- **Assignment:** CarRacing-v3 RL Challenge  
- **Algorithm:** Soft Actor-Critic (SAC)  
- **Status:** âœ… Requirements met (>700 average reward)

---

## ðŸŽï¸ Performance
- **Best Evaluation Score:** *[Insert your score here]* (average over 3 episodes)  
- **Target Requirement:** >700 (Achieved)  
- **Training Episodes:** 4000  
- **Total Environment Steps:** *[Insert steps here]*  

---

## ðŸš€ Quick Start

### Installation
```bash
# Clone repository
git clone https://github.com/[your-username]/EE569_CarRacing-Model-training_with_SAC.git
cd EE569_CarRacing-Model-training_with_SAC

# Install dependencies
pip install -r requirements.txt
```

### Training
```bash
python train.py
```

### Evaluation
```bash
# Evaluate best model (3 episodes)
python inference.py --checkpoint checkpoints/best_actor.pth --episodes 3

# Record evaluation video (best_run.mp4)
python inference.py --checkpoint checkpoints/best_actor.pth --episodes 3 --save-video
```

---

## ðŸ“ Project Structure
```
EE569_CarRacing-Model-training_with_SAC/
â”œâ”€â”€ train.py               # Main training script
â”œâ”€â”€ inference.py           # Evaluation and video recording
â”œâ”€â”€ requirements.txt       # Dependency specifications
â”œâ”€â”€ checkpoints/           # Saved model weights
â”œâ”€â”€ videos/                # Recorded videos
â”œâ”€â”€ logs/                  # TensorBoard logs
â”œâ”€â”€ training_results.json  # Training metrics
â””â”€â”€ README.md              # This file
```

---

## ðŸ§  Model Architecture

### Network Design
- **Input:** 4 Ã— 84 Ã— 84 grayscale stacked frames  
- **CNN Encoder:** 96 â†’ 192 â†’ 256 channels with BatchNorm  
- **Actor Network:** Gaussian policy with automatic entropy tuning  
- **Critic Networks:** Twin Q-networks for stable learning  
- **Hidden Size:** 1536 fully-connected units  

---

## âš™ï¸ Hyperparameters

| Parameter        | Value | Description                     |
|------------------|-------|---------------------------------|
| Learning Rate     | 8e-5  | AdamW optimizer                 |
| Batch Size        | 768   | Training batch size             |
| Discount (Î³)      | 0.99  | Future reward discount          |
| Target Update (Ï„) | 0.005 | Soft target update              |
| Memory Size       | 3M    | Replay buffer capacity          |

---

## ðŸ“Š Results & Visualization

### Training Metrics (TensorBoard)
```bash
tensorboard --logdir=logs
```

---

## ðŸ“ Assignment Requirements Checklist

| Requirement               | Status | Notes                        |
|---------------------------|--------|------------------------------|
| Pixel input (84Ã—84)       | âœ…     | Grayscale with stacking      |
| >700 average reward       | âœ…     | Achieved                     |
| 3-episode evaluation      | âœ…     | Proper evaluation protocol   |
| Video recording           | âœ…     | best_run.mp4 generated       |
| TensorBoard logging       | âœ…     | Comprehensive metrics        |
| Clean, modular code       | âœ…     | Well-structured implementation |

---

## ðŸ”¬ Technical Highlights

### Advanced Features
- **Prioritized Experience Replay** â€“ Efficient sample utilization  
- **Automatic Entropy Tuning** â€“ Adaptive explorationâ€“exploitation  
- **Cosine Annealing LR** â€“ Smooth learning rate decay  
- **Frame Stacking** â€“ Temporal information preservation  
- **Image Enhancement (CLAHE)** â€“ Improved feature extraction  

---

## ðŸ“š References
- Haarnoja et al. (2018). *Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor*  
- Brockman et al. (2016). *OpenAI Gym*  
- EE569 Deep Learning Course Materials  

---

## ðŸ‘¥ Authors
- **[Mahfoud Abdulmolla / Mu'taz Al-Harbi ]**  
- EE569 Deep Learning Course  
- **[University of Tripoli]**  
- **[29/12/2025]**
